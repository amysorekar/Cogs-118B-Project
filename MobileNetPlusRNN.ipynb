{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c62308f1-bdb5-444c-9b22-189cfb344ed9",
   "metadata": {},
   "source": [
    "# MobileNet CNN Feature Extractor and RNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e5808-5e6d-420d-a71f-3551bfa47dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c4311-44e4-4800-8867-dae9d67c92be",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this cell we convert the .wav files into spectrograms. encode the labels, and split the data into training and testing sets (80% and 20% respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62a64a-682d-4f22-bb90-c0b9b6c8b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess audio file into Mel Spectrogram\n",
    "def preprocess_audio_file(file_path, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Converts a .wav file into a Mel Spectrogram, resizes it for InceptionV3, \n",
    "    and normalizes pixel values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        resized_spec = resize(mel_spec_db, target_shape, mode='constant')\n",
    "        rgb_spec = np.stack([resized_spec] * 3, axis=-1) / 255.0  # Normalize to [0, 1]\n",
    "        return rgb_spec\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process directory of sounds into spectrograms and labels\n",
    "def process_directory_to_dataframe(parent_directory, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Processes all .wav files in a directory and its subdirectories,\n",
    "    computes their Mel Spectrograms, and stores them in a DataFrame.\n",
    "    \"\"\"\n",
    "    data, labels = [], []\n",
    "    for root, _, files in os.walk(parent_directory):\n",
    "        label = os.path.basename(root)  # Subdirectory name is the label\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                spectrogram = preprocess_audio_file(file_path, target_shape)\n",
    "                if spectrogram is not None:\n",
    "                    data.append(spectrogram)\n",
    "                    labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Path to the parent directory containing labeled subdirectories of .wav files\n",
    "parent_directory = \"Animal_Sounds\"  # Replace with your dataset directory\n",
    "\n",
    "# Process audio files and labels\n",
    "print(\"Processing audio files...\")\n",
    "X, y = process_directory_to_dataframe(parent_directory)\n",
    "\n",
    "# Encode labels\n",
    "print(\"Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96480fb-4656-4b5a-b875-509d445f0d0b",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Loading pretrained MobileNet CNN and adding in feature extraction layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bf1a2-3516-434f-8302-1136bacc0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNet model\n",
    "print(\"Loading pre-trained MobileNet model...\")\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a feature extractor from the pre-trained model\n",
    "feature_extractor_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu')  # Feature embedding layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0385208-9307-4c9b-8882-e3471cd4876f",
   "metadata": {},
   "source": [
    "Augmenting the data due to small data size to reduce overfitting of model and increase generalization. Then extarcting the features using the CNN we created in the pervious cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7256cca-aafe-410f-a801-6bff23517844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and training\n",
    "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Extract features for training and testing data\n",
    "print(\"Extracting features using the pre-trained MobileNet model...\")\n",
    "X_train_features = feature_extractor_model.predict(X_train)\n",
    "X_test_features = feature_extractor_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59becea-bfb5-4617-88f4-14a89229f8b6",
   "metadata": {},
   "source": [
    "In this next cell, we prepare the data for the RNN, build the Long Short-Term Momory based RNN as follows and compile the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2565836-6753-41c4-88be-fe283929bbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape features for RNN input\n",
    "timesteps = 1  # One timestep per spectrogram\n",
    "X_train_rnn = X_train_features.reshape(X_train_features.shape[0], timesteps, -1)\n",
    "X_test_rnn = X_test_features.reshape(X_test_features.shape[0], timesteps, -1)\n",
    "\n",
    "# Build the RNN model\n",
    "print(\"Building the CNN + RNN hybrid model...\")\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    TimeDistributed(Dense(128, activation='relu'), input_shape=(timesteps, X_train_rnn.shape[2])),\n",
    "    LSTM(128, return_sequences=False),  # LSTM for temporal modeling\n",
    "    Dropout(0.5),\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Classification layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "optimizer = AdamW(learning_rate=0.001, weight_decay=1e-4)\n",
    "\n",
    "rnn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5e5ae-4a4e-4af2-87c9-c36d1c83cda9",
   "metadata": {},
   "source": [
    "Here we are training the model and evaluating it, calculating the accuracy on the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0bb06-0060-4efc-9b64-eb9e5cc6a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training the CNN + RNN hybrid model...\")\n",
    "\n",
    "# Early Stopping to reduce overfitting by stopping training when validation loss does not change for 5 epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Learning Rate Scheduler to reduce LR when validation loss plateaus\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.5,          # Reduce LR by a factor of 0.5\n",
    "    patience=3,          # Wait 3 epochs before reducing LR\n",
    "    verbose=1,\n",
    "    min_lr=1e-6          # Minimum learning rate\n",
    ")\n",
    "\n",
    "history = rnn_model.fit(\n",
    "    X_train_rnn, y_train,\n",
    "    validation_data=(X_test_rnn, y_test),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping,lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = rnn_model.evaluate(X_test_rnn, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save the hybrid model\n",
    "rnn_model.save(\"mobilenet_rnn_hybrid_model.h5\")\n",
    "print(\"Model saved as 'mobilenet_rnn_hybrid_model.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac2261-741a-4bb7-9a3b-730e78a4f425",
   "metadata": {},
   "source": [
    "We plot a report and a confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cfcc6-83cc-496e-8223-1abf0c50b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred_probs = rnn_model.predict(X_test_rnn)  # Predicted probabilities\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted classes\n",
    "y_true = np.argmax(y_test, axis=1)  # True classes\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ea032-b0d1-4fad-ac82-f677820bd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, GlobalAveragePooling2D, Attention\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Preprocess audio file into Mel Spectrogram\n",
    "def preprocess_audio_file(file_path, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Converts a .wav file into a Mel Spectrogram, resizes it for InceptionV3, \n",
    "    and normalizes pixel values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        resized_spec = resize(mel_spec_db, target_shape, mode='constant')\n",
    "        rgb_spec = np.stack([resized_spec] * 3, axis=-1) / 255.0  # Normalize to [0, 1]\n",
    "        return rgb_spec\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process directory of sounds into spectrograms and labels\n",
    "def process_directory_to_dataframe(parent_directory, target_shape=(224, 224)):\n",
    "    \"\"\"\n",
    "    Processes all .wav files in a directory and its subdirectories,\n",
    "    computes their Mel Spectrograms, and stores them in a DataFrame.\n",
    "    \"\"\"\n",
    "    data, labels = [], []\n",
    "    for root, _, files in os.walk(parent_directory):\n",
    "        label = os.path.basename(root)  # Subdirectory name is the label\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                spectrogram = preprocess_audio_file(file_path, target_shape)\n",
    "                if spectrogram is not None:\n",
    "                    data.append(spectrogram)\n",
    "                    labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Path to the parent directory containing labeled subdirectories of .wav files\n",
    "parent_directory = \"Animal_Sounds\"  # Replace with your dataset directory\n",
    "\n",
    "# Process audio files and labels\n",
    "print(\"Processing audio files...\")\n",
    "X, y = process_directory_to_dataframe(parent_directory)\n",
    "\n",
    "# Encode labels\n",
    "print(\"Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85308be-82c9-4455-8c5a-8bc31145136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNet model\n",
    "print(\"Loading pre-trained MobileNet model...\")\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a feature extractor from the pre-trained model\n",
    "feature_extractor_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu')  # Feature embedding layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6bdcc1-d985-4d2c-85d0-3625be79f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and training\n",
    "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Extract features for training and testing data\n",
    "print(\"Extracting features using the pre-trained MobileNet model...\")\n",
    "X_train_features = feature_extractor_model.predict(X_train)\n",
    "X_test_features = feature_extractor_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9c8ec-c46d-40fe-9179-68067d4f3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train Logistic Regression Classifier\n",
    "print(\"Training the Logistic Regression classifier...\")\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,  # Increase max iterations for convergence\n",
    "    random_state=42,\n",
    "    multi_class='multinomial',  # For multi-class classification\n",
    "    solver='lbfgs'              # Recommended solver for multiclass tasks\n",
    ")\n",
    "lr_model.fit(X_train_features, np.argmax(y_train, axis=1))\n",
    "\n",
    "# Evaluate the Model\n",
    "print(\"Evaluating the Logistic Regression classifier...\")\n",
    "y_pred = lr_model.predict(X_test_features)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
